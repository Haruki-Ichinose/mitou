{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e9d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded FP data: 65471 rows, 65 athletes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "CLEAN_PATH = \"/workspace/data/00/StatsAllGroup_cleaned.parquet\"\n",
    "df = pd.read_parquet(CLEAN_PATH)\n",
    "\n",
    "# â˜… 01 ã¯ FP å°‚ç”¨\n",
    "df = df[df[\"position_group\"] == \"FP\"].copy()\n",
    "\n",
    "print(f\"âœ… Loaded FP data: {df.shape[0]} rows, {df['athlete_name'].nunique()} athletes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad718af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Generated timeline: day_type\n",
      "Season    672\n",
      "Off       313\n",
      "Mid        13\n",
      "Name: count, dtype: int64\n",
      "ğŸ“Œ Merged timeline into df\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 0. timelineï¼ˆæ—¥ä»˜ Ã— day_typeï¼‰ç”Ÿæˆ\n",
    "# ========================================\n",
    "all_dates = pd.date_range(df[\"date_\"].min(), df[\"date_\"].max(), freq='D')\n",
    "\n",
    "daily_counts = df.groupby(\"date_\")[\"athlete_id\"].nunique()\n",
    "daily_counts = daily_counts.reindex(all_dates, fill_value=0)\n",
    "\n",
    "total_athletes = df[\"athlete_id\"].nunique()\n",
    "daily_percent = daily_counts / total_athletes * 100\n",
    "\n",
    "OFF_TH = 5\n",
    "MID_TH = 20\n",
    "\n",
    "def label_day(p):\n",
    "    if p < OFF_TH:\n",
    "        return \"Off\"\n",
    "    elif p < MID_TH:\n",
    "        return \"Mid\"\n",
    "    else:\n",
    "        return \"Season\"\n",
    "\n",
    "day_type = daily_percent.apply(label_day)\n",
    "\n",
    "timeline = pd.DataFrame({\n",
    "    \"date_\": all_dates,\n",
    "    \"day_type\": day_type.values\n",
    "})\n",
    "\n",
    "print(\"ğŸ“Œ Generated timeline:\", timeline[\"day_type\"].value_counts())\n",
    "\n",
    "df = df.merge(timeline, on=\"date_\", how=\"left\")\n",
    "print(\"ğŸ“Œ Merged timeline into df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7007268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Season-based player summary created.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 1. Season æ—¥ã®ã¿ä½¿ç”¨ï¼ˆSeason-awareï¼‰\n",
    "# ========================================\n",
    "df_season = df[df[\"day_type\"] == \"Season\"].copy()\n",
    "\n",
    "player_summary = (\n",
    "    df_season.groupby(\"athlete_id\")\n",
    "      .agg(\n",
    "          athlete_name=(\"athlete_name\", \"first\"),\n",
    "          season_count=(\"date_\", \"count\"),\n",
    "          season_unique_days=(\"date_\", \"nunique\"),\n",
    "          first_season_date=(\"date_\", \"min\"),\n",
    "          last_season_date=(\"date_\", \"max\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "player_summary[\"season_duration_days\"] = (\n",
    "    player_summary[\"last_season_date\"] - player_summary[\"first_season_date\"]\n",
    ").dt.days + 1\n",
    "\n",
    "player_summary[\"season_density_ratio\"] = (\n",
    "    player_summary[\"season_unique_days\"] / player_summary[\"season_duration_days\"]\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Œ Season-based player summary created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b15ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ VALID PLAYERSï¼ˆSeason-aware 3ãƒ¶æœˆ45æ—¥ï¼‰: 53 å\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 2. Season ç‰ˆ 3ãƒ¶æœˆ45æ—¥ãƒ«ãƒ¼ãƒ«ã§ valid_players ã‚’æ±ºå®š\n",
    "# ========================================\n",
    "window_days = 90\n",
    "min_days_in_window = 45\n",
    "\n",
    "valid_players = []\n",
    "\n",
    "for athlete_id, sub in df_season.groupby(\"athlete_id\"):\n",
    "    dates = sub[\"date_\"].drop_duplicates().sort_values()\n",
    "    for start in dates:\n",
    "        end = start + timedelta(days=window_days)\n",
    "        if (dates.between(start, end).sum() >= min_days_in_window):\n",
    "            valid_players.append(athlete_id)\n",
    "            break\n",
    "\n",
    "\n",
    "print(f\"ğŸ¯ VALID PLAYERSï¼ˆSeason-aware 3ãƒ¶æœˆ45æ—¥ï¼‰: {len(valid_players)} å\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f2ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_summary_valid = player_summary[\n",
    "    player_summary[\"athlete_id\"].isin(valid_players)\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392cc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Rule1åˆ†å¸ƒï¼š\n",
      "rule1_category\n",
      "full       53\n",
      "exclude     0\n",
      "partial     0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Rule 1ï¼šSeasonå‡ºç¾æ—¥æ•°\n",
    "# ---------------------------------------------------------\n",
    "player_summary_valid[\"season_days\"] = player_summary_valid[\"season_unique_days\"]\n",
    "\n",
    "player_summary_valid[\"rule1_category\"] = pd.cut(\n",
    "    player_summary_valid[\"season_days\"],\n",
    "    bins=[0, 10, 30, 10000],\n",
    "    labels=[\"exclude\", \"partial\", \"full\"]\n",
    ")\n",
    "\n",
    "print(\"âœ” Rule1åˆ†å¸ƒï¼š\")\n",
    "print(player_summary_valid[\"rule1_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e21b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ” Rule2åˆ†å¸ƒï¼š\n",
      "rule2_adjusted\n",
      "full       30\n",
      "partial    23\n",
      "exclude     0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Rule 2ï¼šå¹³å‡è·é›¢ï¼ˆ600 / 1200mé–¾å€¤ï¼‰\n",
    "# ---------------------------------------------------------\n",
    "mean_dist = (\n",
    "    df_season.groupby(\"athlete_id\")[\"total_distance\"]\n",
    "    .mean()\n",
    "    .rename(\"mean_season_distance\")\n",
    ")\n",
    "\n",
    "player_summary_valid = player_summary_valid.merge(\n",
    "    mean_dist, on=\"athlete_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "player_summary_valid[\"rule2_adjusted\"] = player_summary_valid[\"rule1_category\"]\n",
    "\n",
    "player_summary_valid.loc[\n",
    "    player_summary_valid[\"mean_season_distance\"] < 600,\n",
    "    \"rule2_adjusted\"\n",
    "] = \"exclude\"\n",
    "\n",
    "player_summary_valid.loc[\n",
    "    (player_summary_valid[\"mean_season_distance\"] >= 600) &\n",
    "    (player_summary_valid[\"mean_season_distance\"] < 1200),\n",
    "    \"rule2_adjusted\"\n",
    "] = \"partial\"\n",
    "\n",
    "\n",
    "print(\"\\nâœ” Rule2åˆ†å¸ƒï¼š\")\n",
    "print(player_summary_valid[\"rule2_adjusted\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9c2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ” Rule3 ã‚¯ãƒ©ã‚¹ã‚¿å‰²å½“ï¼š {1: 'exclude', 0: 'partial', 2: 'full'}\n",
      "cluster_label\n",
      "partial    29\n",
      "exclude    22\n",
      "full        2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Rule 3ï¼šã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆcluster_center ã§è‡ªå‹•åˆ¤å®šï¼‰\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "cluster_features = player_summary_valid[[\n",
    "    \"season_days\",\n",
    "    \"mean_season_distance\",\n",
    "    \"season_density_ratio\"\n",
    "]].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(cluster_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "player_summary_valid[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "strength = centers.sum(axis=1)\n",
    "ranked_clusters = np.argsort(strength)\n",
    "\n",
    "cluster_to_label = {\n",
    "    ranked_clusters[0]: \"exclude\",\n",
    "    ranked_clusters[1]: \"partial\",\n",
    "    ranked_clusters[2]: \"full\"\n",
    "}\n",
    "\n",
    "player_summary_valid[\"cluster_label\"] = player_summary_valid[\"cluster\"].map(cluster_to_label)\n",
    "\n",
    "print(\"\\nâœ” Rule3 ã‚¯ãƒ©ã‚¹ã‚¿å‰²å½“ï¼š\", cluster_to_label)\n",
    "print(player_summary_valid[\"cluster_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101fc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ğŸ‰ Final é¸æ‰‹åˆ†é¡ï¼ˆvalid_playersã®ã¿ï¼‰\n",
      "==============================\n",
      "final_category\n",
      "full       30\n",
      "partial    23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Final çµ±åˆã‚«ãƒ†ã‚´ãƒª\n",
    "# ---------------------------------------------------------\n",
    "priority = [\"exclude\", \"partial\", \"full\"]\n",
    "\n",
    "def combine_labels(row):\n",
    "    candidates = [row[\"rule2_adjusted\"], row[\"cluster_label\"]]\n",
    "    return max(candidates, key=lambda x: priority.index(x))\n",
    "\n",
    "player_summary_valid[\"final_category\"] = player_summary_valid.apply(combine_labels, axis=1)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"ğŸ‰ Final é¸æ‰‹åˆ†é¡ï¼ˆvalid_playersã®ã¿ï¼‰\")\n",
    "print(\"==============================\")\n",
    "print(player_summary_valid[\"final_category\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f09cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… athlete_id uniqueness OK\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Final sanity check\n",
    "# ---------------------------------------------------------\n",
    "assert player_summary_valid[\"athlete_id\"].is_unique\n",
    "print(\"âœ… athlete_id uniqueness OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa687ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Saved:\n",
      " - /workspace/data/01/fp_player_final_categories.csv\n",
      " - /workspace/data/01/fp_player_final_categories.parquet\n",
      "âœ¨ Notebook 01 å®Œå…¨å®Œäº†ï¼ˆCSV + Parquet ä¿å­˜ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 3. ä¿å­˜ï¼ˆ01ã®å‡ºåŠ›ã¯ã“ã®1ã¤ã ã‘ï¼‰\n",
    "# ========================================\n",
    "PLAYER_DIR = \"/workspace/data/01\"\n",
    "os.makedirs(PLAYER_DIR, exist_ok=True)\n",
    "\n",
    "csv_path = f\"{PLAYER_DIR}/fp_player_final_categories.csv\"\n",
    "parquet_path = f\"{PLAYER_DIR}/fp_player_final_categories.parquet\"\n",
    "\n",
    "player_summary_valid.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "player_summary_valid.to_parquet(parquet_path, index=False)\n",
    "\n",
    "print(\"\\nğŸ“ Saved:\")\n",
    "print(\" -\", csv_path)\n",
    "print(\" -\", parquet_path)\n",
    "print(\"âœ¨ Notebook 01 å®Œå…¨å®Œäº†ï¼ˆCSV + Parquet ä¿å­˜ï¼‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
